{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('deep')\n",
    "sns.set_color_codes('deep')\n",
    "sns.set_context('paper', font_scale=1.5)\n",
    "%matplotlib notebook\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "## Problem 1: Linear Regression Class [40pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = {}\n",
    "    \n",
    "    def get_params(self):\n",
    "        # return best fit params (B-hat) from fit()\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        \"\"\"Set params in subclass\"\"\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # fits linear model supplied from subclass to X and y \n",
    "        # and stores best fit coeffs (b_hat) in params dict\n",
    "        \"\"\"Fit model.\"\"\"\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # get best fit coeffs from params dict and convert to column vector\n",
    "        beta = self.params\n",
    "        beta = np.concatenate(([beta['intercept']], beta['coeffs']))\n",
    "        beta = np.array([beta]).T # convert to column vector\n",
    "        \n",
    "        # prepend the column of ones to design matrix\n",
    "        nrows = X.shape[0]\n",
    "        intercept_ones = np.ones(nrows)\n",
    "        X = np.column_stack((intercept_ones, X))\n",
    "        \n",
    "        # y = X B + epsilon\n",
    "        y_pred = X.dot(beta)\n",
    "        y_pred = y_pred.T[0] # convert back to 1D array R_sq\n",
    "        return y_pred\n",
    "            \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        # score statistics\n",
    "        y_bar = np.mean(y)\n",
    "        SS_E = np.sum((y - y_pred)**2)\n",
    "        SS_T = np.sum((y - y_bar)**2)\n",
    "        R_sq = 1 - SS_E / SS_T\n",
    "        return(R_sq)\n",
    "    \n",
    "    def plot_prediction(self, ax, y_pred, y_test):\n",
    "        ax.plot(y_pred, 'r', label='prediction') # prediction\n",
    "        ax.plot(y_test, 'b', label='test') # test\n",
    "        ax.legend(loc='best')\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: OLS Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(Regression):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.M = 0\n",
    "        super().__init__() # to maintina access to params dict\n",
    "    #    self.M = M # for Ridge. M=0 for OLS by default\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #self.M = 0 # for Ridge. M=0 for OLS by default\n",
    "        # create design matrix (padding with ones column)\n",
    "        if X.ndim == 1: # just duplicate the same observation\n",
    "            X = np.insert(X, 0, 1)\n",
    "            X = np.tile(X, (len(X), 1))\n",
    "        else:\n",
    "            num_rows = X.shape[0]\n",
    "            intercept_ones = np.ones(num_rows)\n",
    "            X = np.column_stack((intercept_ones, X))\n",
    "        \n",
    "        # compute B_hat\n",
    "        X_inv = np.linalg.pinv(X)\n",
    "        y = np.array([y]).T # convert to column vector\n",
    "        B_hat = np.linalg.pinv(X.T.dot(X) + self.M).dot(X.T).dot(y)\n",
    "        # return params\n",
    "        B_hat = B_hat.ravel() # convert to 1D array\n",
    "        self.params['coeffs'] = B_hat[1:]\n",
    "        self.params['intercept'] = B_hat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression(LinearRegression):\n",
    "    def __init__(self, alpha=0.1):\n",
    "        super().__init__() # get access to params dict\n",
    "        self.alpha = self.set_params()\n",
    "        self.M = self.get_M() # overwrite default OLS M=0\n",
    "    \n",
    "    def get_M(self):\n",
    "        # Gamma = alpha * I\n",
    "        # The +1 accounts for extra column of 1's to give I the\n",
    "        # right dimensions\n",
    "        Gamma = self.alpha*np.identity(len(X.T.dot(X)) + 1)\n",
    "        return Gamma.T.dot(Gamma)\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.alpha = kwargs['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parabola(x, **kwargs):\n",
    "    return kwargs['a'] + kwargs['b']\n",
    "\n",
    "#parabola(1.0, width=1.0, trans=-1.0, shift=-1.0)\n",
    "coeffs = {'a':2.0, 'b':4}\n",
    "parabola(1.0, **coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-512-a359710a3386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidgeRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmy_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmy_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-511-440686a2d567>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, alpha)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get access to params dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_M\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# overwrite default OLS M=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-511-440686a2d567>\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'alpha'"
     ]
    }
   ],
   "source": [
    "model = RidgeRegression()\n",
    "my_params = {'alpha':.5}\n",
    "model.set_params(**my_params)\n",
    "model.fit(X, y)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Model Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "dataset = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Poke around inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (506, 13):\n",
      "\n",
      "target (506,):\n",
      "\n",
      "feature_names (13,):\n",
      "\n",
      "DESCR ():\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# just looking at everything stored inside the dict\n",
    "width = 20\n",
    "for k, v in dataset.items():\n",
    "    print(f\"{k} {np.shape(v)}:\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Let's take a look inside the \"empty\" `DESCR` field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  The dataset description in `dataset['DESR']` tells us that there are 14 columns, but there are only 13 in `dataset.data` according to its shape though. This means that the 14th column is probably stored in the only other key whose value is a 1-D array, `dataset['target']` . This is also noted as \"Median Value (attribute 14) is usually the target\" in the `DESCR` field. I'll just tack this on to the end of the 2-D array and display it as a `pandas` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10 # reduce how many rows are shown\n",
    "\n",
    "# I'm not using dot notation to access data and feature names because I am pretending that dataset is a dict and not an sklearn object for this HW.\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "col_names = dataset['feature_names']\n",
    "df = pd.DataFrame(X, columns=col_names)\n",
    "df['target'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ok, so it looks like each row is the stats for a town (or collection of homes?) and each column are some corresponding stats, with the last one being the median price in that particular  town in the  $1000's$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Recasting this as a linear regression problem: for any given town $i$, $y_i$ is the observed target median price corresponding to homes in that town and $x_{ij}$ is the $j$th statistic that was also measured for town $i$, corresponding to the $j$ column in row $i$ of the table shown above. For the $p$ regressors (number of columns, not including the target column), \n",
    "\n",
    "\\begin{align}\n",
    "    y_i = \\sum_{j=0}^{p} x_{ij}\\beta_j + \\epsilon_i\\ , \n",
    "    (i = 1,2,\\dots, m)\\ ,\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### where  $m$ is the number of towns (observations), $\\beta_i$ is some scalar coefficient, $\\epsilon_i$ is/are some unobserved random variable/s that account for influences on $y_i$ other than the collection of regressors $x_i$ that we happen to know about. Setting $x_{i0} = 0$ allows $(\\beta_0)$ to act  as our intercept. In matrix form, all of the $m$ models (number of rows in the table) can compactly be written as\n",
    "\\begin{align}\n",
    "    \\boldsymbol y = \\boldsymbol X \\boldsymbol\\beta + \\boldsymbol\\epsilon\n",
    "    \\ ,\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### where $\\boldsymbol y$ is a column vector with length $m$, $\\boldsymbol X$ is an $m\\times n$ (design) matrix (where $n=p+1$, since it's just the data table above with a first column of ones and minus the target column), and $\\boldsymbol\\beta$ and $\\boldsymbol\\epsilon$ are also column  vectors of length $m$ composed of the $\\beta_i$'s and $\\epsilon_i$'s mentioned above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Game plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Alright, I'm going to use the first 405 models ($\\approx 80\\%$ of the data) as my training set to determine the best fit coefficients $\\boldsymbol{\\hat\\beta}$ found from OLS and Ridge to test on the reminaing 101 models, respectively, and score how well each predictive model does on the remaing 101 models in predicting the target housing price $y_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-465-5ac5c44ab060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"OLS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ridge\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRidgeRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-464-6c745d5b9fb7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, alpha)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get access to params dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_M\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# overwrite default OLS M=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-464-6c745d5b9fb7>\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'alpha'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 253,
       "width": 826
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_test_split(data, target, f=0.8):\n",
    "    # split data into training and test set\n",
    "    \n",
    "    num_train = int(round(f*len(X))) # number of training models\n",
    "    \n",
    "    # training set\n",
    "    X_train = data[0:num_train, :]\n",
    "    y_train = target[0:num_train]\n",
    "    \n",
    "    # test set\n",
    "    X_test = data[num_train:, :]\n",
    "    y_test = target[num_train:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, f=0.8)\n",
    "\n",
    "# run fits and display\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4), sharey=True)\n",
    "alpha = 0.1\n",
    "model_names = [\"OLS\", \"Ridge\"]\n",
    "models = [LinearRegression(), RidgeRegression(alpha)]\n",
    "for ax, model, model_name in zip(axes, models, model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    beta = model.get_params()\n",
    "    print(f\"Model: {model_name}\\n------------\\n\"\n",
    "          f\"R^2 score: {score}\\n\"\n",
    "          f\"Best fit params: {beta}\\n\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    ax = model.plot_prediction(ax, y_pred, y_test)\n",
    "    ax.set_title(model_name)\n",
    "    ax.legend(title=f'$R^2 = {score:.4f}$')\n",
    "\n",
    "axes[0].set_ylabel(\"Median housing price ($1000's)\")\n",
    "fig.text(0.48, -0.01, 'town number', fontsize=12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Visualize Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 [10pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Create a module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Included in directory as `MathCS207.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Import a whole module and use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: {'a': 1.0, 'b': 2.0}\n",
      "----------------------------\n",
      "addition (a + b): 3.0\n",
      "subtraction (a - b): -1.0\n",
      "multiplication (a*b): 2.0\n",
      "division (a/b): 0.5\n"
     ]
    }
   ],
   "source": [
    "import MathCS207\n",
    "\n",
    "# inputs\n",
    "inputs = {'a':1., 'b':2.}\n",
    "\n",
    "# show output from module\n",
    "print(\n",
    "    f\"inputs: {inputs}\\n----------------------------\\n\"\n",
    "    f\"addition (a + b): {MathCS207.add(**inputs)}\\n\"\n",
    "    f\"subtraction (a - b): {MathCS207.subtract(**inputs)}\\n\"\n",
    "    f\"multiplication (a*b): {MathCS207.multiply(**inputs)}\\n\"\n",
    "    f\"division (a/b): {MathCS207.divide(**inputs)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Import a single function from a module and use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "from MathCS207 import add\n",
    "\n",
    "print(add(**inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Import a module by creating an alias of it and then use the alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "import MathCS207 as mathcs\n",
    "\n",
    "print(mathcs.add(**inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: List every function definition inside the module MathCS207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'add', 'divide', 'multiply', 'subtract']\n"
     ]
    }
   ],
   "source": [
    "print(dir(MathCS207))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Bank Account Revisited [50pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Defining `SAVINGS` and `CHECKING` bank accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class AccountType(Enum):\n",
    "    SAVINGS = 1\n",
    "    CHECKING = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Create a BankAccount class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BankAccount():\n",
    "    \n",
    "    def __init__(self, owner, accountType):\n",
    "        self.owner = owner\n",
    "        self.accountType = accountType\n",
    "        \n",
    "    def withdraw(self, amount): \n",
    "        return \n",
    "    \n",
    "    def deposit(self, amount):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Write a class BankUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BankUser():\n",
    "    \n",
    "    def __init__(self, owner):\n",
    "        self.owner = owner\n",
    "    \n",
    "    def addAccount(self, accountType):\n",
    "        \n",
    "    def getBalance(self, accountType):\n",
    "    \n",
    "    def deposit(self, accountType, amount): \n",
    "        \n",
    "    def withdraw(self, accountType, amount):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New balance: $349.50\n"
     ]
    }
   ],
   "source": [
    "def make_withdraw(balance):\n",
    "    def update_balance(debit):\n",
    "        # places the variable 'balance' in the outer scope of\n",
    "        # make_withdraw \n",
    "        # into the inner scope of update_balance\n",
    "        nonlocal balance\n",
    "        if debit <= balance:\n",
    "            balance -= debit\n",
    "            print(f\"New balance: ${balance:.2f}\")\n",
    "        else:\n",
    "            print(\"Please enter a withdrawl amount \" \n",
    "                  \"less than or equal to your current balance.\")\n",
    "    return update_balance\n",
    "\n",
    "init_balance = 500 # initial balance\n",
    "withdraw_amount = 150.50 # amount to withdraw\n",
    "\n",
    "wd = make_withdraw(init_balance)\n",
    "wd(withdraw_amount)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#fc151b",
    "navigate_text": "#92a2be",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "319px",
    "width": "686px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
